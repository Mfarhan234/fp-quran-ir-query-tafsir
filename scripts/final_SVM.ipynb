{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84da54c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Path berhasil diset.\n",
      "ğŸ“‚ Root Dir: c:\\Kuliah ITS Farhan\\Semester 3\\A_Final_Project\\ML_DM\\fp-quran-ir-query-tafsir\n",
      "ğŸ“‚ Data Dir: c:\\Kuliah ITS Farhan\\Semester 3\\A_Final_Project\\ML_DM\\fp-quran-ir-query-tafsir\\data\\processed\n",
      "\n",
      "ğŸ” Checking files:\n",
      "   CSV exists: True\n",
      "   - Path: c:\\Kuliah ITS Farhan\\Semester 3\\A_Final_Project\\ML_DM\\fp-quran-ir-query-tafsir\\data\\processed\\dataset_training_FULL_COMPLETE.csv\n",
      "   Embedding exists: True\n",
      "   SVM exists: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rank_bm25 import BM25Okapi\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.svm import SVC # Untuk type-checking\n",
    "\n",
    "# --- KONFIGURASI PATH ---\n",
    "# Notebook ada di folder scripts/, jadi naik 1 level ke root\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data', 'processed')\n",
    "\n",
    "# FILE-FILE YANG DIBUTUHKAN\n",
    "CSV_PATH = os.path.join(DATA_DIR, 'dataset_training_FULL_COMPLETE.csv')\n",
    "EMB_FILE = os.path.join(MODEL_DIR, 'corpus_embeddings.pt')\n",
    "SVM_PATH = os.path.join(MODEL_DIR, 'svm (3) (1).pkl') # Model Teman Anda\n",
    "\n",
    "# URUTAN FITUR WAJIB (Sesuai isi file .pkl teman Anda)\n",
    "SVM_FEATURES = ['sbert_sim', 'overlap_score', 'jaccard_score', 'bm25_score'] \n",
    "\n",
    "print(\"âœ… Path berhasil diset.\")\n",
    "print(f\"ğŸ“‚ Root Dir: {ROOT_DIR}\")\n",
    "print(f\"ğŸ“‚ Data Dir: {DATA_DIR}\")\n",
    "print(f\"\\nğŸ” Checking files:\")\n",
    "print(f\"   CSV exists: {os.path.exists(CSV_PATH)}\")\n",
    "print(f\"   - Path: {CSV_PATH}\")\n",
    "print(f\"   Embedding exists: {os.path.exists(EMB_FILE)}\")\n",
    "print(f\"   SVM exists: {os.path.exists(SVM_PATH)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8cc8cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Memuat Dataset Lengkap...\n",
      "âœ… Data Termuat: 6031 dokumen tafsir unik.\n"
     ]
    }
   ],
   "source": [
    "print(\"âš™ï¸ Memuat Dataset Lengkap...\")\n",
    "\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f\"File {CSV_PATH} tidak ditemukan!\")\n",
    "\n",
    "# 1. Baca CSV\n",
    "df_full = pd.read_csv(CSV_PATH)\n",
    "df_full.columns = df_full.columns.str.strip().str.lower()\n",
    "\n",
    "# 2. Ambil Tafsir Unik (Corpus Pencarian)\n",
    "df_index = df_full.drop_duplicates(subset=['text']).copy()\n",
    "unique_tafsirs = df_index['text'].astype(str).tolist()\n",
    "\n",
    "# 3. Buat Kamus Metadata\n",
    "metadata_map = {}\n",
    "for _, row in df_index.iterrows():\n",
    "    key = str(row['text']).strip()\n",
    "    metadata_map[key] = {\n",
    "        'lokasi': row.get('ayat_asal', '?'),\n",
    "        'arabic': row.get('arabic', ''),\n",
    "        'trans': row.get('translation', '')\n",
    "    }\n",
    "\n",
    "print(f\"âœ… Data Termuat: {len(unique_tafsirs)} dokumen tafsir unik.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5827c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Memuat Embedding & SBERT...\n",
      "âœ… Embedding Lama Berhasil Diload.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'c:\\Kuliah ITS Farhan\\Semester 3\\A_Final_Project\\ML_DM\\fp-quran-ir-query-tafsir\\models\\sbert_finetuned_quran' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SBERT Loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"âš™ï¸ Memuat Embedding & SBERT...\")\n",
    "\n",
    "# 1. Load Embedding Lama (.pt)\n",
    "if os.path.exists(EMB_FILE):\n",
    "    corpus_embeddings = torch.load(EMB_FILE, map_location='cpu')\n",
    "    print(f\"âœ… Embedding Lama Berhasil Diload.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"File corpus_embeddings.pt hilang!\")\n",
    "\n",
    "# 2. Load SBERT (Hanya untuk encode query)\n",
    "SBERT_FOLDER = os.path.join(MODEL_DIR, 'sbert_finetuned_quran')\n",
    "try:\n",
    "    sbert_model = SentenceTransformer(SBERT_FOLDER, device='cpu')\n",
    "    print(\"âœ… SBERT Loaded.\")\n",
    "except:\n",
    "    sbert_model = SentenceTransformer(SBERT_FOLDER, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b03ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Memuat Model SVM...\n",
      "âœ… Model SVM berhasil dimuat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Farhan\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"âš™ï¸ Memuat Model SVM...\")\n",
    "\n",
    "if not os.path.exists(SVM_PATH):\n",
    "    raise FileNotFoundError(f\"Model {SVM_PATH} tidak ditemukan.\")\n",
    "\n",
    "# 1. Load Model\n",
    "try:\n",
    "    # SVM biasanya disimpan dengan joblib, atau kadang dengan pickle biasa\n",
    "    try:\n",
    "        svm_model = joblib.load(SVM_PATH)\n",
    "    except:\n",
    "        with open(SVM_PATH, 'rb') as f:\n",
    "            svm_model = pickle.load(f)\n",
    "            \n",
    "    print(\"âœ… Model SVM berhasil dimuat.\")\n",
    "    \n",
    "    # Cek apakah model ini mendukung predict_proba (untuk skor 0-1)\n",
    "    if not hasattr(svm_model, 'predict_proba'):\n",
    "         print(\"âš ï¸ Model SVM tidak mendukung 'predict_proba'. Kita akan menggunakan 'decision_function'.\")\n",
    "         svm_use_decision_function = True\n",
    "    else:\n",
    "         svm_use_decision_function = False\n",
    "         \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Gagal memuat model SVM: {e}\")\n",
    "    raise SystemExit(\"Model SVM gagal dimuat. Cek inkompatibilitas versi Sklearn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943b3176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Menyiapkan BM25...\n",
      "âœ… BM25 Siap.\n"
     ]
    }
   ],
   "source": [
    "print(\"âš™ï¸ Menyiapkan BM25...\")\n",
    "\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "except:\n",
    "    stop_words = set(['yang', 'dan', 'di'])\n",
    "\n",
    "def clean_tokens(text):\n",
    "    text = str(text).lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    return [w for w in text.split() if w not in stop_words]\n",
    "\n",
    "# Build Index BM25\n",
    "corpus_tokens = [clean_tokens(t) for t in unique_tafsirs]\n",
    "bm25 = BM25Okapi(corpus_tokens)\n",
    "\n",
    "# Pastikan fungsi clean_tokens dapat diakses di cell lain\n",
    "clean_func = clean_tokens \n",
    "\n",
    "print(\"âœ… BM25 Siap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ec6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cari_svm(query_text, threshold=0.0): # Threshold default 0.0 karena kita pakai decision_function atau proba\n",
    "    print(f\"\\nğŸ” QUERY: '{query_text}'\")\n",
    "    print(f\"âš™ï¸ Threshold yang digunakan: {threshold:.4f} (Menggunakan Decision Function atau Probabilitas)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Retrieval (SBERT)\n",
    "    query_vec = sbert_model.encode(query_text, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_vec, corpus_embeddings, top_k=50)[0]\n",
    "    \n",
    "    candidates = []\n",
    "    q_toks = clean_func(query_text)\n",
    "    \n",
    "    # 2. Hitung Fitur\n",
    "    for hit in hits:\n",
    "        idx = hit['corpus_id']\n",
    "        txt = unique_tafsirs[idx]\n",
    "        \n",
    "        t_toks = clean_func(txt)\n",
    "        sq, st = set(q_toks), set(t_toks)\n",
    "        ov = len(sq & st) / len(sq) if sq else 0\n",
    "        jac = len(sq & st) / (len(sq | st) + 1e-9)\n",
    "        bm25_s = bm25.get_batch_scores(q_toks, [idx])[0]\n",
    "        \n",
    "        candidates.append({\n",
    "            'text_key': txt,\n",
    "            'sbert_sim': hit['score'],\n",
    "            'bm25_score': bm25_s,\n",
    "            'overlap_score': ov,\n",
    "            'jaccard_score': jac\n",
    "        })\n",
    "    \n",
    "    # 3. Prediksi dengan SVM\n",
    "    df_cand = pd.DataFrame(candidates)\n",
    "    \n",
    "    # SUSUN KOLOM SESUAI URUTAN MODEL TEMAN ANDA (WAJIB!)\n",
    "    X_pred = df_cand[SVM_FEATURES]\n",
    "    \n",
    "    # Random Forest predict_proba (ambil probabilitas kelas 1)\n",
    "    if hasattr(svm_model, 'predict_proba') and not svm_use_decision_function:\n",
    "        # Jika mendukung proba (skor 0-1)\n",
    "        scores = svm_model.predict_proba(X_pred)[:, 1]\n",
    "    else:\n",
    "        # Jika tidak mendukung proba, gunakan decision_function (skor -inf s.d +inf)\n",
    "        scores = svm_model.decision_function(X_pred)\n",
    "        # Jika decision function, kita set threshold ke 0.0 (nilai tengah)\n",
    "        threshold = 0.0\n",
    "        \n",
    "    df_cand['final_score'] = scores\n",
    "    \n",
    "    # 4. Filter & Tampilkan\n",
    "    results = df_cand[df_cand['final_score'] > threshold].sort_values('final_score', ascending=False)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        # Jika tidak ada yang > threshold, tampilkan yang paling mendekati\n",
    "        print(\"âŒ Tidak ada yang melewati threshold. Menampilkan Top 3 skor tertinggi:\")\n",
    "        results = df_cand.sort_values('final_score', ascending=False).head(3)\n",
    "        \n",
    "    else:\n",
    "        print(f\"âœ… Top 3 Hasil (Engine: SVM):\\n\")\n",
    "    \n",
    "    for i, row in enumerate(results.head(3).iterrows()):\n",
    "        _, data = row\n",
    "        key = str(data['text_key']).strip()\n",
    "        score = data['final_score']\n",
    "        info = metadata_map.get(key)\n",
    "        \n",
    "        print(f\"ğŸ… [RANK {i+1}] Skor: {score:.4f}\")\n",
    "        if info:\n",
    "            print(f\"ğŸ“ {info['lokasi']}\")\n",
    "            print(f\"ğŸ‡¸ğŸ‡¦ {info['arabic'][:60]}...\")\n",
    "            print(f\"ğŸ‡®ğŸ‡© {info['trans'][:100]}...\")\n",
    "        print(f\"ğŸ’¬ TAFSIR: {key[:100]}...\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe981826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” QUERY: 'Kisah sapi betina bani israil'\n",
      "âš™ï¸ Threshold yang digunakan: 0.0000 (Menggunakan Decision Function atau Probabilitas)\n",
      "============================================================\n",
      "âœ… Top 3 Hasil (Engine: SVM):\n",
      "\n",
      "ğŸ… [RANK 1] Skor: 0.1802\n",
      "ğŸ“ QS. Al-Qaá¹£aá¹£ : Ayat 23\n",
      "ğŸ‡¸ğŸ‡¦ ÙˆÙÙ„ÙÙ…Ù‘ÙØ§ ÙˆÙØ±ÙØ¯Ù Ù…ÙØ§Û¤Ø¡Ù Ù…ÙØ¯Ù’ÙŠÙÙ†Ù ÙˆÙØ¬ÙØ¯Ù Ø¹ÙÙ„ÙÙŠÙ’Ù‡Ù Ø§ÙÙ…Ù‘ÙØ©Ù‹ Ù…Ù‘ÙÙ†...\n",
      "ğŸ‡®ğŸ‡© Ketika sampai di sumber air negeri Madyan, dia menjumpai di sana sekumpulan orang yang sedang member...\n",
      "ğŸ’¬ TAFSIR: Dan ketika sudah berjalan cukup lama dan jauh, Musa sampai di sumber air negeri Madyan. Dia menjumpa...\n",
      "--------------------------------------------------\n",
      "ğŸ… [RANK 2] Skor: 0.1801\n",
      "ğŸ“ QS. Al-Baqarah  : Ayat 113\n",
      "ğŸ‡¸ğŸ‡¦ ÙˆÙÙ‚ÙØ§Ù„ÙØªÙ Ø§Ù„Ù’ÙŠÙÙ‡ÙÙˆÙ’Ø¯Ù Ù„ÙÙŠÙ’Ø³ÙØªÙ Ø§Ù„Ù†Ù‘ÙØµÙ°Ø±Ù°Ù‰ Ø¹ÙÙ„Ù°Ù‰ Ø´ÙÙŠÙ’Ø¡ÙÛ– ÙˆÙ‘ÙÙ‚...\n",
      "ğŸ‡®ğŸ‡© Orang Yahudi berkata, â€œOrang Nasrani itu tidak menganut sesuatu (agama yang benar)â€ dan orang-orang ...\n",
      "ğŸ’¬ TAFSIR: Dan orang Yahudi berkata, â€œOrang Nasrani itu tidak memiliki sesuatu, yakni pegangan berupa agama yan...\n",
      "--------------------------------------------------\n",
      "ğŸ… [RANK 3] Skor: 0.1801\n",
      "ğŸ“ QS. Al-MÄ'idah : Ayat 21\n",
      "ğŸ‡¸ğŸ‡¦ ÙŠÙ°Ù‚ÙÙˆÙ’Ù…Ù Ø§Ø¯Ù’Ø®ÙÙ„ÙÙˆØ§ Ø§Ù„Ù’Ø§ÙØ±Ù’Ø¶Ù Ø§Ù„Ù’Ù…ÙÙ‚ÙØ¯Ù‘ÙØ³ÙØ©Ù Ø§Ù„Ù‘ÙØªÙÙŠÙ’ ÙƒÙØªÙØ¨Ù ...\n",
      "ğŸ‡®ğŸ‡© Wahai kaumku, masuklah ke tanah suci (Baitulmaqdis) yang telah Allah tentukan bagimu208) dan janganl...\n",
      "ğŸ’¬ TAFSIR: Nabi Musa selanjutnya berkata kepada kaumnya, â€œWahai kaumku! Masuklah ke tanah suci, yaitu tanah Pal...\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ” QUERY: 'Hukum warisan bagi perempuan'\n",
      "âš™ï¸ Threshold yang digunakan: 0.0000 (Menggunakan Decision Function atau Probabilitas)\n",
      "============================================================\n",
      "âœ… Top 3 Hasil (Engine: SVM):\n",
      "\n",
      "ğŸ… [RANK 1] Skor: 0.7824\n",
      "ğŸ“ QS. An-NisÄ'  : Ayat 11\n",
      "ğŸ‡¸ğŸ‡¦ ÙŠÙÙˆÙ’ØµÙÙŠÙ’ÙƒÙÙ…Ù Ø§Ù„Ù„Ù‘Ù°Ù‡Ù ÙÙÙŠÙ’Ù“ Ø§ÙÙˆÙ’Ù„ÙØ§Ø¯ÙÙƒÙÙ…Ù’ Ù„ÙÙ„Ø°Ù‘ÙÙƒÙØ±Ù Ù…ÙØ«Ù’Ù„Ù Ø­...\n",
      "ğŸ‡®ğŸ‡© Allah mensyariatkan (mewajibkan) kepadamu tentang (pembagian warisan untuk) anak-anakmu, (yaitu) bag...\n",
      "ğŸ’¬ TAFSIR: Setelah ayat sebelumnya menjelaskan dampak orang yang mengabaikan hak orang lain, ayat ini menjelask...\n",
      "--------------------------------------------------\n",
      "ğŸ… [RANK 2] Skor: 0.6462\n",
      "ğŸ“ QS. An-NisÄ'  : Ayat 8\n",
      "ğŸ‡¸ğŸ‡¦ ÙˆÙØ§ÙØ°ÙØ§ Ø­ÙØ¶ÙØ±Ù Ø§Ù„Ù’Ù‚ÙØ³Ù’Ù…ÙØ©Ù Ø§ÙÙˆÙ„ÙÙˆØ§ Ø§Ù„Ù’Ù‚ÙØ±Ù’Ø¨Ù°Ù‰ ÙˆÙØ§Ù„Ù’ÙŠÙØªÙ°Ù…Ù°Ù‰ Ùˆ...\n",
      "ğŸ‡®ğŸ‡© Apabila (saat) pembagian itu hadir beberapa kerabat,144) anak-anak yatim, dan orang-orang miskin, be...\n",
      "ğŸ’¬ TAFSIR: Setelah menjelaskan ketentuan hak warisan bagi kaum perempuan, maka pada ayat ini Allah memberi peri...\n",
      "--------------------------------------------------\n",
      "ğŸ… [RANK 3] Skor: 0.4571\n",
      "ğŸ“ QS. An-NisÄ'  : Ayat 127\n",
      "ğŸ‡¸ğŸ‡¦ ÙˆÙÙŠÙØ³Ù’ØªÙÙÙ’ØªÙÙˆÙ’Ù†ÙÙƒÙ ÙÙÙ‰ Ø§Ù„Ù†Ù‘ÙØ³ÙØ§Û¤Ø¡ÙÛ—  Ù‚ÙÙ„Ù Ø§Ù„Ù„Ù‘Ù°Ù‡Ù ÙŠÙÙÙ’ØªÙÙŠÙ’ÙƒÙ...\n",
      "ğŸ‡®ğŸ‡© Mereka meminta fatwa kepada engkau (Nabi Muhammad) tentang perempuan. Katakanlah, â€œAllah memberi fat...\n",
      "ğŸ’¬ TAFSIR: Dan mereka meminta fatwa, yaitu penjelasan hukum, kepadamu, wahai Muhammad, tentang berbagai persoal...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Uji coba Query Kisah\n",
    "cari_svm(\"Kisah sapi betina bani israil\")\n",
    "# Uji coba Query Fiqih\n",
    "cari_svm(\"Hukum warisan bagi perempuan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d1938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
