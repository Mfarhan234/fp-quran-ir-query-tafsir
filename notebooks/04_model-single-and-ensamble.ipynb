{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-05T03:52:34.432755Z",
     "iopub.status.busy": "2025-12-05T03:52:34.432527Z",
     "iopub.status.idle": "2025-12-05T03:52:42.351139Z",
     "shell.execute_reply": "2025-12-05T03:52:42.350528Z",
     "shell.execute_reply.started": "2025-12-05T03:52:34.432735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARY\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:52:42.352844Z",
     "iopub.status.busy": "2025-12-05T03:52:42.352371Z",
     "iopub.status.idle": "2025-12-05T03:52:42.356978Z",
     "shell.execute_reply": "2025-12-05T03:52:42.356254Z",
     "shell.execute_reply.started": "2025-12-05T03:52:42.352822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# KONFIGURASI PATH & PARAMETER\n",
    "DATA_DIR = Path(\"/kaggle/input/fp-quran-relevance-features\")\n",
    "\n",
    "features_path = DATA_DIR / \"query_tafsir_features (1).csv\"\n",
    "\n",
    "# folder output model di /kaggle/working\n",
    "OUT_DIR = Path(\"/kaggle/working/models\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:52:42.357780Z",
     "iopub.status.busy": "2025-12-05T03:52:42.357617Z",
     "iopub.status.idle": "2025-12-05T03:52:42.377347Z",
     "shell.execute_reply": "2025-12-05T03:52:42.376699Z",
     "shell.execute_reply.started": "2025-12-05T03:52:42.357766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_ranking_metrics(y_true: np.ndarray, y_scores: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Menghitung MAP (Global Average Precision) dan AUC-ROC\n",
    "    dipakai sebagai proxy metrik ranking ketika tidak ada Query ID.\n",
    "    \"\"\"\n",
    "    map_score = average_precision_score(y_true, y_scores)\n",
    "    auc_roc = roc_auc_score(y_true, y_scores)\n",
    "    return {\n",
    "        \"MAP (Global AP)\": map_score,\n",
    "        \"AUC-ROC\": auc_roc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:52:42.378129Z",
     "iopub.status.busy": "2025-12-05T03:52:42.377917Z",
     "iopub.status.idle": "2025-12-05T03:52:42.561463Z",
     "shell.execute_reply": "2025-12-05T03:52:42.560805Z",
     "shell.execute_reply.started": "2025-12-05T03:52:42.378105Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset fitur dimuat dari: /kaggle/input/fp-quran-relevance-features/query_tafsir_features (1).csv\n",
      " Total pasangan query-tafsir: 184,655\n",
      "\n",
      "Distribusi label:\n",
      "label\n",
      "0    0.826379\n",
      "1    0.173621\n",
      "Name: proporsi, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA FITUR\n",
    "try:\n",
    "    df_features = pd.read_csv(features_path)\n",
    "    print(f\" Dataset fitur dimuat dari: {features_path}\")\n",
    "    print(f\" Total pasangan query-tafsir: {len(df_features):,}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" Error: File fitur tidak ditemukan di {features_path}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Kolom fitur & label\n",
    "FEATURE_COLS = [\n",
    "    \"feat_tfidf_similarity\",\n",
    "    \"feat_sbert_similarity\",\n",
    "    \"feat_keyword_overlap\",\n",
    "]\n",
    "TARGET_COL = \"label\"\n",
    "\n",
    "X = df_features[FEATURE_COLS].values\n",
    "y = df_features[TARGET_COL].values\n",
    "\n",
    "print(\"\\nDistribusi label:\")\n",
    "print(df_features[TARGET_COL].value_counts(normalize=True).rename(\"proporsi\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:52:42.563420Z",
     "iopub.status.busy": "2025-12-05T03:52:42.563137Z",
     "iopub.status.idle": "2025-12-05T03:52:42.682829Z",
     "shell.execute_reply": "2025-12-05T03:52:42.682188Z",
     "shell.execute_reply.started": "2025-12-05T03:52:42.563402Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data dibagi Train/Test (80/20) dan dinormalisasi untuk model linear.\n",
      "  X_train: (147724, 3), X_test: (36931, 3)\n",
      "  scale_pos_weight (XGBoost) ≈ 4.76\n"
     ]
    }
   ],
   "source": [
    "# SPLIT TRAIN/TEST + SCALING\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n Data dibagi Train/Test (80/20) dan dinormalisasi untuk model linear.\")\n",
    "print(f\"  X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "\n",
    "# untuk XGBoost (imbalance-aware)\n",
    "value_counts = pd.Series(y).value_counts()\n",
    "scale_pos_weight = value_counts[0] / value_counts[1]\n",
    "print(f\"  scale_pos_weight (XGBoost) ≈ {scale_pos_weight:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:52:42.683959Z",
     "iopub.status.busy": "2025-12-05T03:52:42.683665Z",
     "iopub.status.idle": "2025-12-05T03:52:42.690432Z",
     "shell.execute_reply": "2025-12-05T03:52:42.689648Z",
     "shell.execute_reply.started": "2025-12-05T03:52:42.683934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    # SINGLE (linear, pakai data scaled)\n",
    "    'LogisticRegression': LogisticRegression(\n",
    "        random_state=RANDOM_SEED,\n",
    "        solver='liblinear',\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        kernel='linear',\n",
    "        probability=True,\n",
    "        random_state=RANDOM_SEED,\n",
    "        class_weight='balanced'\n",
    "        # kalau terlalu lama, bisa tambahkan: max_iter=2000\n",
    "    ),\n",
    "\n",
    "    # ENSEMBLE (tree-based, pakai data asli)\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    # XGBoost pakai GPU\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        random_state=RANDOM_SEED,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        tree_method='gpu_hist',      # GPU\n",
    "        predictor='gpu_predictor',\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=400,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    "    ),\n",
    "\n",
    "    # LightGBM pakai GPU\n",
    "    'LightGBM': lgb.LGBMClassifier(\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        class_weight='balanced',\n",
    "        device_type='gpu'   # pakai GPU di Kaggle\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:52:42.691999Z",
     "iopub.status.busy": "2025-12-05T03:52:42.691805Z",
     "iopub.status.idle": "2025-12-05T04:09:30.343252Z",
     "shell.execute_reply": "2025-12-05T04:09:30.342505Z",
     "shell.execute_reply.started": "2025-12-05T03:52:42.691983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Melatih Model: LogisticRegression ...\n",
      "LogisticRegression selesai. MAP: 0.9001, AUC: 0.9531, Waktu: 0.20 detik\n",
      "\n",
      " Melatih Model: SVM ...\n",
      "SVM selesai. MAP: 0.8998, AUC: 0.9528, Waktu: 988.87 detik\n",
      "\n",
      " Melatih Model: RandomForest ...\n",
      "RandomForest selesai. MAP: 0.8858, AUC: 0.9496, Waktu: 8.90 detik\n",
      "\n",
      " Melatih Model: XGBoost ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [04:09:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [04:09:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [04:09:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [04:09:22] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost selesai. MAP: 0.9035, AUC: 0.9569, Waktu: 1.65 detik\n",
      "\n",
      " Melatih Model: LightGBM ...\n",
      "[LightGBM] [Info] Number of positive: 25648, number of negative: 122076\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 147724, number of used features: 3\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 3 dense feature groups (0.56 MB) transferred to GPU in 0.001091 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "LightGBM selesai. MAP: 0.9016, AUC: 0.9558, Waktu: 8.00 detik\n"
     ]
    }
   ],
   "source": [
    "# TRAIN & EVALUASI PER MODEL\n",
    "\n",
    "for name, model in models.items():\n",
    "    # pilih data scaled / unscaled\n",
    "    if name in ['LogisticRegression', 'SVM']:\n",
    "        X_train_data = X_train_scaled\n",
    "        X_test_data = X_test_scaled\n",
    "    else:\n",
    "        X_train_data = X_train\n",
    "        X_test_data = X_test\n",
    "\n",
    "    print(f\"\\n Melatih Model: {name} ...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.fit(X_train_data, y_train)\n",
    "    y_scores = model.predict_proba(X_test_data)[:, 1]\n",
    "\n",
    "    metrics = calculate_ranking_metrics(y_test, y_scores)\n",
    "    end_time = time.time()\n",
    "    metrics['Training_Time (s)'] = end_time - start_time\n",
    "    results[name] = metrics\n",
    "    trained_models[name] = model\n",
    "\n",
    "    print(f\"{name} selesai. \"\n",
    "          f\"MAP: {metrics['MAP (Global AP)']:.4f}, \"\n",
    "          f\"AUC: {metrics['AUC-ROC']:.4f}, \"\n",
    "          f\"Waktu: {metrics['Training_Time (s)']:.2f} detik\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T04:33:54.733174Z",
     "iopub.status.busy": "2025-12-05T04:33:54.732444Z",
     "iopub.status.idle": "2025-12-05T04:33:54.896132Z",
     "shell.execute_reply": "2025-12-05T04:33:54.895518Z",
     "shell.execute_reply.started": "2025-12-05T04:33:54.733147Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RINGKASAN KINERJA MODEL (Diurutkan berdasarkan MAP)\n",
      "                    MAP (Global AP)  AUC-ROC  Training_Time (s)\n",
      "XGBoost                      0.9035   0.9569             1.6549\n",
      "LightGBM                     0.9016   0.9558             8.0048\n",
      "LogisticRegression           0.9001   0.9531             0.2034\n",
      "SVM                          0.8998   0.9528           988.8723\n",
      "RandomForest                 0.8858   0.9496             8.9020\n",
      "\n",
      "Tabel hasil disimpan ke: /kaggle/working/models/model_comparison_results.csv\n",
      "\n",
      "Best overall model: XGBoost (type=ensemble)\n",
      "Disimpan: model_LogisticRegression.pkl\n",
      "Disimpan: model_SVM.pkl\n",
      "Disimpan: model_RandomForest.pkl\n",
      "Disimpan: model_XGBoost.pkl\n",
      "Disimpan: model_LightGBM.pkl\n",
      "Disimpan: best_relevance_model.pkl\n"
     ]
    }
   ],
   "source": [
    "feature_names = df_features.drop(columns=['label']).columns.tolist()\n",
    "\n",
    "# RINGKASAN HASIL\n",
    "df_results = pd.DataFrame(results).T\n",
    "df_results_sorted = df_results.sort_values(by=\"MAP (Global AP)\", ascending=False)\n",
    "\n",
    "print(\"RINGKASAN KINERJA MODEL (Diurutkan berdasarkan MAP)\")\n",
    "print(df_results_sorted.to_string(float_format=\"%.4f\"))\n",
    "\n",
    "results_path = OUT_DIR / \"model_comparison_results.csv\"\n",
    "df_results_sorted.to_csv(results_path, index=True)\n",
    "print(f\"\\nTabel hasil disimpan ke: {results_path}\")\n",
    "\n",
    "def get_model_meta(name: str):\n",
    "    if name in [\"LogisticRegression\", \"SVM\"]:\n",
    "        return {\"type\": \"single\", \"use_scaled\": True}\n",
    "    else:\n",
    "        return {\"type\": \"ensemble\", \"use_scaled\": False}\n",
    "\n",
    "best_model_name = df_results_sorted.index[0]\n",
    "best_model = trained_models[best_model_name]\n",
    "best_meta = get_model_meta(best_model_name)\n",
    "\n",
    "print(f\"\\nBest overall model: {best_model_name} (type={best_meta['type']})\")\n",
    "\n",
    "def save_model(obj: dict, path: Path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(f\"Disimpan: {path.name}\")\n",
    "\n",
    "# simpan semua model\n",
    "for name, clf in trained_models.items():\n",
    "    meta = get_model_meta(name)\n",
    "\n",
    "    obj = {\n",
    "        \"model\": clf,\n",
    "        \"scaler\": scaler,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"model_name\": name,\n",
    "        \"type\": meta[\"type\"],\n",
    "        \"use_scaled\": meta[\"use_scaled\"],\n",
    "    }\n",
    "\n",
    "    save_model(obj, OUT_DIR / f\"model_{name}.pkl\")\n",
    "\n",
    "# simpan best overall\n",
    "save_model(\n",
    "    {\n",
    "        \"model\": best_model,\n",
    "        \"scaler\": scaler,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"best_model_name\": best_model_name,\n",
    "        \"type\": best_meta[\"type\"],\n",
    "        \"use_scaled\": best_meta[\"use_scaled\"],\n",
    "    },\n",
    "    OUT_DIR / \"best_relevance_model.pkl\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8921791,
     "sourceId": 14002526,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8921801,
     "sourceId": 14002545,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8921810,
     "sourceId": 14002556,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
